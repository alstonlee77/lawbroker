# app.py
# -*- coding: utf-8 -*-
import os
import io
import re
import time
import json
import random
import hashlib
from pathlib import Path
from typing import List, Tuple, Dict, Optional

import pandas as pd
import requests
import streamlit as st


# =========================
# åŸºæœ¬è¨­å®š
# =========================
st.set_page_config(page_title="æ¨¡æ“¬è€ƒèˆ‡é¡Œåº«ç·´ç¿’", layout="wide")
st.title("ğŸ“˜ æ¨¡æ“¬è€ƒèˆ‡é¡Œåº«ç·´ç¿’")

# ä½ çš„ä¸‰å¤§é ˜åŸŸæ ¹ç›®éŒ„ï¼ˆäººèº« / å¤–å¹£ / æŠ•è³‡å‹ éƒ½åœ¨é€™åº•ä¸‹ï¼‰
BASE_ROOT = Path("/Users/lch/lawbroker/è€ƒç…§AI")   # â† è·¯å¾‘ä¸åŒè«‹æ”¹é€™è¡Œ

# åƒ…ç”¨æ–¼æ’åºç½®é ‚ï¼›å¯¦éš›ä»¥ç›®éŒ„æƒæç‚ºæº–
DEFAULT_DOMAIN_NAMES = ["äººèº«", "å¤–å¹£", "æŠ•è³‡å‹"]
VALID_EXTS = (".xlsx", ".xls")  # .xls éœ€ xlrd<2.0ï¼›æˆ–æŠŠæª”æ¡ˆå¦å­˜ç‚º .xlsx


# =========================
# ç®¡ç†è€…åˆ¤æ–·ï¼ˆä¸ä¾è³´ secretsï¼‰
# =========================
def resolve_admin() -> bool:
    try:
        qp = st.query_params
        admin_val = qp.get("admin", None)
        if admin_val is not None:
            if isinstance(admin_val, list):
                admin_val = admin_val[0]
            if str(admin_val) == "1":
                return True
    except Exception:
        pass
    if os.getenv("ADMIN", "0") == "1" or os.getenv("STREAMLIT_ADMIN", "0") == "1":
        return True
    try:
        return str(st.secrets.get("ADMIN", "0")) == "1"
    except Exception:
        return False

def safe_rerun():
    try:
        st.rerun()
    except AttributeError:
        try:
            st.experimental_rerun()
        except Exception:
            pass

IS_ADMIN = resolve_admin()


# =========================
# AI è©³è§£ï¼šåªåœ¨éŒ¯é¡Œæ™‚è§¸ç™¼ï¼ˆé è¨­èµ°æœ¬æ©Ÿ Ollamaï¼‰
# =========================
AI_PROVIDER = os.getenv("LLM_PROVIDER", "ollama").lower()    # openai / ollama
OPENAI_MODEL = os.getenv("OPENAI_MODEL", "gpt-4o-mini")
OLLAMA_MODEL = os.getenv("OLLAMA_MODEL", "qwen2.5:3b-instruct")
OLLAMA_ENDPOINT = os.getenv("OLLAMA_ENDPOINT", "http://127.0.0.1:11434/api/generate")

def _hash_key(payload: dict) -> str:
    s = json.dumps(payload, ensure_ascii=False, sort_keys=True)
    return hashlib.sha256(s.encode("utf-8")).hexdigest()[:16]

def llm_explain(question: str,
                options: dict,
                correct_letters: List[str],
                user_letters: List[str],
                tag: str = "",
                domain: str = "",
                file_name: str = "",
                sheet_name: str = "") -> str:
    """
    å‘¼å«èªè¨€æ¨¡å‹ç”¢ç”Ÿä¸­æ–‡è©³è§£ï¼ˆç°¡æ½”ã€å¯æ•™å­¸ï¼›ä¸æš´éœ²æ€ç¶­éç¨‹ï¼‰ã€‚
    åƒ…åœ¨éŒ¯é¡Œæ™‚è¢«å‘¼å«ã€‚
    """
    prompt = f"""
ä½ æ˜¯ä¸€ä½ä¿éšª/é‡‘èè€ƒè©¦è¬›è§£è€å¸«ã€‚è«‹ç”¨ç¹é«”ä¸­æ–‡ï¼Œçµ¦å‡ºã€Œç²¾ç°¡ä¸”å¯æ•™å­¸ã€çš„è§£æã€‚
é™åˆ¶ï¼š
- åªä»¥é¡Œç›®èˆ‡é¸é …ç‚ºä¾æ“šï¼›ä¸ç¢ºå®šæ™‚è«‹æŒ‡å‡ºè³‡æ–™ä¸è¶³ã€‚
- çµæ§‹ 3 æ®µï¼š1) ç‚ºä½•æ­£è§£æ˜¯ {''.join(correct_letters)}ï¼›2) æœ¬é¡Œå¸¸è¦‹èª¤è§£èˆ‡æ’é™¤ï¼›3) ä¸€å¥å¸¶èµ°é‡é»ã€‚
- åš´ç¦æé€ æœªåœ¨é¡Œå¹¹èˆ‡é¸é …å‡ºç¾çš„å°ˆæœ‰åè©æˆ–æ•¸å€¼ã€‚
- 120â€“220 å­—ã€‚

[é¡Œç›®é ˜åŸŸ] {domain}
[ä¾†æº] æª”æ¡ˆï¼š{file_name} / åˆ†é ï¼š{sheet_name} / æ¨™ç±¤ï¼š{tag}
[é¡Œå¹¹]
{question}

[é¸é …]
{options}

[æ­£ç¢ºç­”æ¡ˆ] {''.join(correct_letters)}
[ä½¿ç”¨è€…ä½œç­”] {''.join(user_letters) if user_letters else 'ï¼ˆæœªä½œç­”ï¼‰'}
"""
    try:
        if AI_PROVIDER == "openai":
            try:
                from openai import OpenAI
            except Exception:
                return "ï¼ˆAIè©³è§£ç„¡æ³•å•Ÿå‹•ï¼šè«‹å…ˆå®‰è£ openai å¥—ä»¶æˆ–è¨­å®š OPENAI_API_KEYï¼‰"
            client = OpenAI()
            resp = client.chat.completions.create(
                model=OPENAI_MODEL,
                messages=[
                    {"role": "system",
                     "content": "You provide concise explanations without revealing chain-of-thought. Output only the final explanation."},
                    {"role": "user", "content": prompt}
                ],
                temperature=0.2,
                max_tokens=300,
            )
            return (resp.choices[0].message.content or "").strip()
        else:
            payload = {"model": OLLAMA_MODEL, "prompt": prompt, "temperature": 0.2, "stream": False}
            r = requests.post(OLLAMA_ENDPOINT, json=payload, timeout=120)
            r.raise_for_status()
            data = r.json()
            return (data.get("response") or "").strip()
    except Exception as e:
        return f"ï¼ˆAIè©³è§£ç”¢ç”Ÿå¤±æ•—ï¼š{e}ï¼‰"

def get_ai_explanation(qrow: pd.Series,
                       user_letters: List[str],
                       option_cols: List[str]) -> str:
    """
    é™„å¸¶å¿«å–çš„ AI è©³è§£ã€‚åªåœ¨éŒ¯é¡Œæ™‚è¢«ä¸Šå±¤å‘¼å«ã€‚
    """
    if "llm_cache" not in st.session_state:
        st.session_state.llm_cache = {}

    opts = {}
    for idx, col in enumerate(option_cols):
        txt = str(qrow.get(col, "")).strip()
        if not txt:
            continue
        letter = chr(ord('A') + idx)
        opts[letter] = txt

    payload = {
        "id": str(qrow.get("ID", "")),
        "question": str(qrow.get("Question", "")),
        "options": opts,
        "gold": list(str(qrow.get("Answer", "")).strip()),
        "user": user_letters,
        "provider": AI_PROVIDER,
        "model": OPENAI_MODEL if AI_PROVIDER == "openai" else OLLAMA_MODEL
    }
    key = _hash_key(payload)
    if key in st.session_state.llm_cache:
        return st.session_state.llm_cache[key]

    text = llm_explain(
        question=payload["question"],
        options=payload["options"],
        correct_letters=payload["gold"],
        user_letters=payload["user"],
        tag=str(qrow.get("Tag", "")),
        domain=str(st.session_state.get("current_domain", "")),
        file_name=os.path.basename(str(qrow.get("__file__", ""))),
        sheet_name=str(qrow.get("__sheet__", "")),
    )
    st.session_state.llm_cache[key] = text
    return text


# =========================
# é¡Œåº«è¼‰å…¥ï¼šå–®è¡¨æ­£è¦åŒ–
# =========================
def _normalize_bank_df(df: pd.DataFrame) -> Tuple[pd.DataFrame, List[str]]:
    """æŠŠå–®ä¸€å·¥ä½œè¡¨çš„é¡Œåº«æ¬„ä½æ­£è¦åŒ–ï¼ˆæ“´å……ï¼šç­”æ¡ˆé¸é …1..5 / A..E / ç”²ä¹™ä¸™ä¸ / å…¨å½¢æ•¸å­— ç­‰ï¼‰ã€‚"""
    df = df.copy()
    df.columns = [str(c).strip() for c in df.columns]

    # ---- å¸¸è¦‹æ¬„ä½å°æ˜  ----
    col_map = {
        "ç·¨è™Ÿ": "ID","é¡Œç›®ç·¨è™Ÿ":"ID", "é¡Œç›®": "Question", "é¡Œå¹¹": "Question", "é¡Œç›®å…§å®¹": "Question", "é¡Œç›®æ•˜è¿°": "Question",
        "ç­”æ¡ˆ": "Answer", "æ­£ç¢ºç­”æ¡ˆ": "Answer", "æ¨™æº–ç­”æ¡ˆ": "Answer",
        "é¡Œå‹": "Type", "é¡å‹": "Type",
        "è§£é‡‹èªªæ˜": "Explanation", "è§£æ": "Explanation", "è©³è§£": "Explanation", "èªªæ˜": "Explanation",
        "æ¨™ç±¤": "Tag", "ç« ç¯€": "Tag", "ç§‘ç›®": "Tag",
        "åœ–ç‰‡": "Image", "åœ–ç‰‡é€£çµ": "Image",
    }
    df = df.rename(columns={c: col_map.get(c, c) for c in df.columns})

    # ---- é¸é …æ¬„åµæ¸¬èˆ‡ rename æˆ OptionA..OptionE ----
    fw = str.maketrans("ï¼¡ï¼¢ï¼£ï¼¤ï¼¥ï¼‘ï¼’ï¼“ï¼”ï¼•", "ABCDE12345")
    cn_to_letter = {"ä¸€": "A", "äºŒ": "B", "ä¸‰": "C", "å››": "D", "äº”": "E",
                    "ç”²": "A", "ä¹™": "B", "ä¸™": "C", "ä¸": "D", "æˆŠ": "E"}

    def to_letter_from_header(h: str) -> Optional[str]:
        # ä¾‹ï¼šç­”æ¡ˆé¸é …1ã€é¸é …1ã€é¸1ã€é …1ã€1ã€ç­”æ¡ˆé¸é …Aã€Aã€(A)ã€ï¼ˆAï¼‰
        s = str(h).strip().replace(" ", "")
        s = s.translate(fw).upper()

        # ç›´æ¥ A~E æˆ– (A) / ï¼ˆAï¼‰
        m = re.fullmatch(r"[ï¼ˆ(]?([A-E])[)ï¼‰]?", s)
        if m:
            return m.group(1)

        # å¸¶å‰ç¶´ï¼šç­”æ¡ˆé¸é …A / é¸é …A / é¸A / é …A
        m = re.fullmatch(r"(?:ç­”æ¡ˆ)?(?:é¸é …|é¸|é …)?([A-E])", s)
        if m:
            return m.group(1)

        # 1~5 å°æ‡‰ A~Eï¼ˆå«å…¨å½¢ï¼‰
        m = re.fullmatch(r"(?:ç­”æ¡ˆ)?(?:é¸é …|é¸|é …)?([1-5])", s)
        if m:
            return "ABCDE"[int(m.group(1)) - 1]

        # ä¸­æ–‡æ•¸å­—/ç”²ä¹™ä¸™ä¸æˆŠ
        m = re.fullmatch(r"(?:ç­”æ¡ˆ)?(?:é¸é …|é¸|é …)?([ä¸€äºŒä¸‰å››äº”ç”²ä¹™ä¸™ä¸æˆŠ])", s)
        if m:
            return cn_to_letter.get(m.group(1))
        return None

    rename_map: Dict[str, str] = {}
    seen_letters: set = set()
    for col in list(df.columns):
        letter = to_letter_from_header(col)
        if letter and letter not in seen_letters:
            rename_map[col] = f"Option{letter}"
            seen_letters.add(letter)

    if rename_map:
        df = df.rename(columns=rename_map)

    # çµ„å‡ºæœ€å¾Œçš„é¸é …æ¬„ä½æ¸…å–®ï¼ˆç…§ A~E æ’åºï¼Œåƒ…ä¿ç•™å­˜åœ¨çš„ï¼‰
    option_cols = [f"Option{L}" for L in "ABCDE" if f"Option{L}" in df.columns]
    if len(option_cols) < 2:
        raise ValueError("é¡Œåº«è‡³å°‘éœ€è¦ 2 å€‹é¸é …æ¬„ï¼ˆä¾‹å¦‚ OptionA/OptionB æˆ– ç­”æ¡ˆé¸é …1/ç­”æ¡ˆé¸é …2ï¼‰ã€‚")

    # ---- åŸºæœ¬æ¬„ä½è£œç©º + å»ç©ºç™½ ----
    for c in ["ID", "Question", "Answer", "Type", "Explanation", "Tag", "Image", *option_cols]:
        if c in df.columns:
            df[c] = df[c].fillna("").astype(str).str.strip()

    # ---- è‹¥æ²’æœ‰ Answer æˆ– Answer å…¨ç©ºï¼šä»¥ã€Œ*ã€åœ¨é¸é …å…§æ¨å°ç­”æ¡ˆ ----
    if "Answer" not in df.columns or df["Answer"].eq("").all():
        answers, types = [], []
        for i, r in df.iterrows():
            starred_letters: List[str] = []
            for idx, col in enumerate(option_cols):
                txt = str(r[col]).strip()
                if txt.startswith("*"):
                    starred_letters.append(chr(ord("A") + idx))
                    df.at[i, col] = txt.lstrip("*").strip()
            if len(starred_letters) == 0:
                answers.append("")
                types.append("SC")
            elif len(starred_letters) == 1:
                answers.append("".join(starred_letters))
                types.append("SC")
            else:
                answers.append("".join(starred_letters))
                types.append("MC")
        df["Answer"] = answers
        if "Type" not in df.columns:
            df["Type"] = types

    # ---- å¿…è¦æ¬„ä½æª¢æŸ¥èˆ‡æ­£è¦åŒ– ----
    for col in ["ID", "Question", "Answer"]:
        if col not in df.columns:
            raise ValueError(f"ç¼ºå°‘å¿…è¦æ¬„ä½ï¼š{col}")

    if "Type" not in df.columns:
        df["Type"] = "SC"
    df["Type"] = df["Type"].astype(str).str.upper().str.strip()
    df["Answer"] = (df["Answer"].astype(str)
                               .str.upper()
                               .str.replace(" ", "", regex=False))

    for c in ["Tag", "Explanation", "Image"]:
        if c not in df.columns:
            df[c] = ""

    # è‡³å°‘å…©å€‹éç©ºé¸é …
    def option_count(row) -> int:
        return sum(1 for c in option_cols if str(row.get(c, "")).strip() != "")
    df = df[df["Answer"].str.len() > 0].copy()
    df = df[df.apply(option_count, axis=1) >= 2].copy()

    return df, option_cols


@st.cache_data(show_spinner=False)
def load_bank_multi_files(
    file_sheet_pairs: List[Tuple[str, str]],
    autofill_tag_with_sheet: bool = False,
) -> Tuple[pd.DataFrame, List[str]]:
    """
    è®€å–ã€Œå¤šå€‹ Excel + å¤šå€‹åˆ†é ã€ä¸¦åˆä½µï¼Œå›å‚³ (åˆä½µå¾Œé¡Œåº«, é¸é …æ¬„ä½æ¸…å–®)ã€‚
    æœƒé™„ä¸Š __file__ / __sheet__ æ¬„ä½ä»¥è¿½è¹¤ä¾†æºã€‚
    """
    if not file_sheet_pairs:
        raise ValueError("æœªé¸å–ä»»ä½•æª”æ¡ˆ/åˆ†é ã€‚")

    merged_list: List[pd.DataFrame] = []
    first_opt_cols: Optional[List[str]] = None

    from collections import defaultdict
    group: Dict[str, List[str]] = defaultdict(list)
    for f, sh in file_sheet_pairs:
        group[f].append(sh)

    for fpath, sheets in group.items():
        try:
            xls = pd.ExcelFile(fpath)
        except Exception as e:
            raise RuntimeError(f"ç„¡æ³•é–‹å•Ÿæª”æ¡ˆï¼š{fpath}\n{e}\nï¼ˆ.xls è«‹å®‰è£ xlrd<2.0 æˆ–æ”¹å­˜ .xlsxï¼‰")

        sheets_to_read = sheets or xls.sheet_names
        for sh in sheets_to_read:
            try:
                df_raw = pd.read_excel(xls, sheet_name=sh)
            except Exception as e:
                raise RuntimeError(f"è®€å–åˆ†é å¤±æ•—ï¼š{fpath} :: {sh}\n{e}")

            df_norm, opt_cols = _normalize_bank_df(df_raw)
            if autofill_tag_with_sheet:
                df_norm["Tag"] = df_norm["Tag"].apply(lambda v: v if str(v).strip() else str(sh))
            df_norm["__file__"] = str(fpath)
            df_norm["__sheet__"] = str(sh)
            merged_list.append(df_norm)
            if first_opt_cols is None:
                first_opt_cols = opt_cols

    if not merged_list:
        raise ValueError("é¸å–çš„æª”æ¡ˆ/åˆ†é ç‚ºç©ºã€‚")

    merged = pd.concat(merged_list, ignore_index=True)
    return merged, first_opt_cols or []


# =========================
# å‡ºé¡Œ/è©•åˆ†è¼”åŠ©
# =========================
def sample_paper(df: pd.DataFrame, n: int, tags: List[str] | None = None) -> pd.DataFrame:
    pool = df.copy()
    if tags and "Tag" in pool.columns:
        pool = pool[pool["Tag"].isin(tags)]
    if len(pool) == 0:
        raise ValueError("æ²’æœ‰ç¬¦åˆæ¢ä»¶çš„é¡Œç›®ã€‚")
    n = min(n, len(pool))
    return pool.sample(n=n, random_state=random.randint(1, 10_000)).reset_index(drop=True)

def build_display_options(row: pd.Series, option_cols: List[str], shuffle: bool = True) -> List[str]:
    items = []
    for idx, col in enumerate(option_cols):
        txt = str(row.get(col, "")).strip()
        if not txt:
            continue
        letter = chr(ord('A') + idx)
        items.append(f"{letter}. {txt}")
    if shuffle:
        random.shuffle(items)
    return items

def parse_choice_to_letters(picked) -> List[str]:
    if isinstance(picked, str):
        picked = [picked]
    letters = []
    for it in picked or []:
        head = str(it).split(".", 1)[0].strip().upper()
        if head and head[0].isalpha():
            letters.append(head[0])
    return letters

def grade(paper: pd.DataFrame, answers: Dict[int, List[str]]) -> tuple[pd.DataFrame, int]:
    rows, score = [], 0
    for i, r in paper.iterrows():
        gold = sorted(list(set(str(r["Answer"]))))
        pred = sorted(list(set(answers.get(i, []))))
        correct = (gold == pred)
        score += int(correct)
        rows.append({
            "ID": r["ID"],
            "Tag": r.get("Tag", ""),
            "Question": r["Question"],
            "Your Answer": "".join(pred),
            "Correct Answer": "".join(gold),
            "Correct": "âœ…" if correct else "âŒ",
            "Explanation": r.get("Explanation", ""),
            "File": r.get("__file__", ""),
            "Sheet": r.get("__sheet__", ""),
        })
    return pd.DataFrame(rows), score


# =========================
# å´æ¬„ï¼šé ˜åŸŸ â†’ æª”æ¡ˆ â†’ åˆ†é  â†’ å‡ºé¡Œè¨­å®šï¼ˆAI åªåœ¨éŒ¯é¡Œæ™‚ï¼‰
# =========================
with st.sidebar:
    st.subheader("ğŸ“‚ é ˜åŸŸé¸æ“‡")
    if not BASE_ROOT.exists():
        st.error(f"æ‰¾ä¸åˆ°æ ¹ç›®éŒ„ï¼š{BASE_ROOT}")
        st.stop()

    subdirs = [d for d in BASE_ROOT.iterdir() if d.is_dir()]
    sorted_subdirs = sorted(
        subdirs, key=lambda p: (DEFAULT_DOMAIN_NAMES.index(p.name) if p.name in DEFAULT_DOMAIN_NAMES else 999, p.name)
    )
    domain_names = [p.name for p in sorted_subdirs] or DEFAULT_DOMAIN_NAMES
    domain = st.selectbox("é¸æ“‡é ˜åŸŸ", options=domain_names, index=0 if domain_names else 0)
    st.session_state.current_domain = domain

    domain_path = BASE_ROOT / domain
    excel_files = sorted([str(p) for p in domain_path.glob("**/*") if p.suffix.lower() in VALID_EXTS])

    st.subheader("ğŸ“„ æª”æ¡ˆé¸æ“‡")
    files_selected = st.multiselect("é¸æ“‡ä¸€å€‹æˆ–å¤šå€‹ Excel æª”", options=excel_files)

    # æƒæåˆ†é 
    sheet_options: List[str] = []
    file_sheet_map: Dict[str, List[str]] = {}
    for f in files_selected:
        try:
            xls = pd.ExcelFile(f)
            file_sheet_map[f] = xls.sheet_names
            sheet_options.extend([f"{Path(f).name} :: {sh}" for sh in xls.sheet_names])
        except Exception as e:
            st.warning(f"ç„¡æ³•è®€å–ï¼š{f}\n{e}")

    st.subheader("ğŸ“‘ åˆ†é é¸æ“‡")
    picked_pairs_display = st.multiselect(
        "é¸æ“‡è¦è¼‰å…¥çš„åˆ†é ï¼ˆä¸é¸ï¼æŠŠæ‰€é¸æª”æ¡ˆçš„æ‰€æœ‰åˆ†é éƒ½è¼‰å…¥ï¼‰",
        options=sheet_options
    )

    def parse_pairs(selected_display: List[str]) -> List[Tuple[str, str]]:
        if not selected_display:
            pairs = []
            for f, sheets in file_sheet_map.items():
                for sh in sheets:
                    pairs.append((f, sh))
            return pairs
        pairs = []
        name_to_file = {Path(f).name: f for f in file_sheet_map.keys()}
        for item in selected_display:
            try:
                fname, sh = [s.strip() for s in item.split("::", 1)]
                fpath = name_to_file.get(fname)
                if fpath:
                    pairs.append((fpath, sh))
            except Exception:
                continue
        return pairs

    file_sheet_pairs = parse_pairs(picked_pairs_display)

    autofill_tag = st.checkbox("æ²’æœ‰ Tag çš„é¡Œç›®ï¼Œç”¨åˆ†é åä½œç‚º Tag", value=False)

    st.subheader("ğŸ§° å‡ºé¡Œè¨­å®š")
    mode = st.radio("æ¨¡å¼", ["ç·´ç¿’", "æ¨¡è€ƒ"], horizontal=True)

    tag_placeholder = st.empty()  # ä¹‹å¾Œå¡« options
    num_q = st.number_input("é¡Œæ•¸", min_value=1, max_value=500, value=30)
    time_min = st.number_input("é™æ™‚ï¼ˆåˆ†ï¼Œ0=ä¸é™æ™‚ï¼‰", min_value=0, max_value=240, value=0)
    shuffle_options = st.checkbox("äº‚åºé¡¯ç¤ºé¸é …", value=True)

    st.subheader("ğŸ§  AI è©³è§£ï¼ˆåƒ…éŒ¯é¡Œï¼‰")
    ai_enable = st.checkbox("å•Ÿç”¨ AI ç”¢ç”Ÿè©³è§£ï¼ˆåªåœ¨éŒ¯é¡Œæ™‚ï¼‰", value=True)

    start_btn = st.button("â–¶ é–‹å§‹/é‡æŠ½")


# =========================
# è¼‰å…¥é¡Œåº«ï¼ˆè·¨æª”æ¡ˆ + è·¨åˆ†é ï¼‰
# =========================
df_bank, option_cols = None, []
if files_selected:
    try:
        df_bank, option_cols = load_bank_multi_files(file_sheet_pairs, autofill_tag_with_sheet=autofill_tag)
    except Exception as e:
        st.error(f"è¼‰å…¥é¡Œåº«å¤±æ•—ï¼š\n{e}")
        st.stop()
else:
    st.info("è«‹å…ˆåœ¨å·¦å´é¸æ“‡é ˜åŸŸèˆ‡æª”æ¡ˆï¼ˆå¯å¤šé¸ï¼‰ï¼Œå†é¸åˆ†é ã€‚")
    st.stop()

# Tag é¸å–®ï¼ˆé˜²å‘†ï¼‰
with st.sidebar:
    if "Tag" in df_bank.columns:
        all_tags = sorted(
            t for t in df_bank["Tag"].dropna().astype(str).map(str.strip).tolist()
            if t and t.lower() != "nan"
        )
    else:
        all_tags = []
    picked_tags = tag_placeholder.multiselect("é¸æ“‡ç« ç¯€/æ¨™ç±¤ï¼ˆå¯å¤šé¸ï¼›ä¸é¸=å…¨é¡Œåº«ï¼‰", options=all_tags, default=[])


# =========================
# åˆå§‹åŒ–/é–‹å§‹ä¸€å ´è€ƒè©¦
# =========================
def start_new_session(df: pd.DataFrame):
    try:
        paper = sample_paper(df, int(st.session_state.num_q), st.session_state.picked_tags)
    except Exception as e:
        st.error(str(e))
        st.stop()
    st.session_state.paper = paper
    st.session_state.start_ts = time.time()
    st.session_state.time_limit = int(st.session_state.time_min) * 60
    st.session_state.session_id = str(int(st.session_state.start_ts))
    st.session_state.answers = {}
    st.session_state.display_map = {}
    st.session_state.submitted = False

st.session_state.num_q = int(num_q)
st.session_state.time_min = int(time_min)
st.session_state.picked_tags = picked_tags

if start_btn or "paper" not in st.session_state:
    start_new_session(df_bank)
    if start_btn:
        safe_rerun()

paper: pd.DataFrame = st.session_state.paper
session_id: str = st.session_state.session_id


# =========================
# å€’æ•¸èˆ‡æ™‚é–“æ§åˆ¶
# =========================
elapsed = int(time.time() - st.session_state.start_ts)
remain = max(0, (st.session_state.time_limit or 0) - elapsed)
time_up = (st.session_state.time_limit and remain == 0)
if st.session_state.time_limit:
    st.info(f"â±ï¸ å‰©é¤˜æ™‚é–“ï¼š{remain // 60:02d}:{remain % 60:02d}")
if time_up and not st.session_state.submitted:
    st.warning("æ™‚é–“åˆ°ï¼ç³»çµ±å·²è‡ªå‹•äº¤å·ã€‚")
    st.session_state.submitted = True


# =========================
# é¡Œç›®æ¸²æŸ“ï¼ˆç·´ç¿’æ¨¡å¼éŒ¯é¡Œå³æ™‚ AIï¼‰
# =========================
for idx, row in paper.iterrows():
    with st.container(border=True):
        st.markdown(f"**Q{idx+1}. {row['Question']}**")
        src_file = Path(str(row.get('__file__', ''))).name
        src_sheet = str(row.get('__sheet__', ''))
        st.caption(f"ä¾†æºï¼š{src_file} / {src_sheet}")

        img_url = str(row.get("Image", "")).strip()
        if img_url:
            st.image(img_url, use_column_width=True)

        display = st.session_state.display_map.get(idx)
        if display is None:
            display = build_display_options(row, option_cols, shuffle=shuffle_options)
            st.session_state.display_map[idx] = display

        qtype = (str(row.get("Type", "SC")).upper().strip() or "SC")
        key_prefix = f"{session_id}_q_{idx}"
        disabled = (st.session_state.submitted or time_up)

        if qtype == "MC":
            picked = st.multiselect("ï¼ˆè¤‡é¸ï¼‰", options=display, key=key_prefix, disabled=disabled)
            letters = parse_choice_to_letters(picked)
        else:
            choice = st.radio("ï¼ˆå–®é¸ï¼‰", options=display, key=key_prefix, disabled=disabled)
            letters = parse_choice_to_letters(choice)

        st.session_state.answers[idx] = letters

        # ç·´ç¿’æ¨¡å¼ï¼šåƒ…éŒ¯é¡Œæ™‚å‡º AI è©³è§£
        if mode == "ç·´ç¿’" and not disabled and letters is not None:
            gold = sorted(list(set(str(row["Answer"]))))
            pred = sorted(list(set(letters)))
            if pred == gold:
                st.success(f"âœ… æ­£ç¢ºï¼ˆç­”æ¡ˆï¼š{''.join(gold)}ï¼‰")
                expl = str(row.get("Explanation", "")).strip()
                if expl:
                    st.info(f"è©³è§£ï¼š{expl}")
            else:
                st.error(f"âŒ éŒ¯èª¤ï¼ˆæ­£è§£ï¼š{''.join(gold)}ï¼‰")
                expl = str(row.get("Explanation", "")).strip()
                if expl:
                    st.info(f"è©³è§£ï¼š{expl}")
                if ai_enable:
                    with st.spinner("AI æ­£åœ¨ç‚ºéŒ¯é¡Œç”¢ç”Ÿè©³è§£â€¦"):
                        ai_text = get_ai_explanation(row, pred, option_cols)
                    if ai_text:
                        st.info(f"ğŸ§  AIè©³è§£ï¼ˆéŒ¯é¡Œï¼‰ï¼š\n\n{ai_text}")

st.divider()


# =========================
# äº¤å·èˆ‡çµæœï¼ˆåƒ…å°éŒ¯é¡Œç”¢ç”Ÿ AI æ¬„ï¼‰
# =========================
submit_clicked = st.button("ğŸ“¥ äº¤å·ä¸¦çœ‹æˆç¸¾", use_container_width=True, disabled=st.session_state.submitted)
if submit_clicked:
    st.session_state.submitted = True

if st.session_state.submitted:
    result_df, score = grade(paper, st.session_state.answers)
    st.subheader("æˆç¸¾")
    st.metric("å¾—åˆ†", f"{score} / {len(paper)}")

    if ai_enable:
        ai_texts = []
        for i, r in paper.iterrows():
            gold = sorted(list(set(str(r["Answer"]))))
            pred = sorted(list(set(st.session_state.answers.get(i, []))))
            if pred != gold:  # åªé‡å°éŒ¯é¡Œ
                ai_texts.append(get_ai_explanation(r, pred, option_cols))
            else:
                ai_texts.append("")
        result_df["AI Explanation (Wrong Only)"] = ai_texts

    st.dataframe(result_df, use_container_width=True, hide_index=True)

    @st.cache_data
    def to_csv(df: pd.DataFrame) -> bytes:
        return df.to_csv(index=False).encode("utf-8-sig")

    st.download_button(
        "â¬‡ï¸ ä¸‹è¼‰ä½œç­”æ˜ç´°ï¼ˆCSVï¼‰",
        data=to_csv(result_df),
        file_name=f"exam_result_{session_id}.csv",
        mime="text/csv"
    )

    st.caption("æç¤ºï¼šèª¿æ•´å·¦å´è¨­å®šä¸¦æŒ‰ã€Œé–‹å§‹/é‡æŠ½ã€å³å¯é–‹æ–°å ´æ¬¡ã€‚")
else:
    st.caption("å¡«å®Œç­”æ¡ˆå¾ŒæŒ‰ä¸‹æ–¹æŒ‰éˆ•äº¤å·ï¼›æˆ–åˆ°æ™‚æœƒè‡ªå‹•äº¤å·ã€‚")
